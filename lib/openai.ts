import OpenAI from 'openai';

// OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (í™˜ê²½ ë³€ìˆ˜ ì²´í¬)
export const openai = process.env.OPENAI_API_KEY 
  ? new OpenAI({
      apiKey: process.env.OPENAI_API_KEY,
    })
  : null;

// ì±—ë´‡ ì‘ë‹µ ìƒì„± í•¨ìˆ˜
export async function generateChatbotResponse(
  userMessage: string,
  context: string,
  conversationHistory: Array<{role: 'user' | 'assistant', content: string}> = []
): Promise<string> {
  // OpenAI API í‚¤ê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì‘ë‹µ ë°˜í™˜
  if (!openai) {
    return 'ì£„ì†¡í•©ë‹ˆë‹¤. AI ì„œë¹„ìŠ¤ê°€ ì¼ì‹œì ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì •ìš°íŠ¹ìˆ˜ì½”íŒ… ë‹´ë‹¹ìì—ê²Œ ì§ì ‘ ë¬¸ì˜í•´ ì£¼ì„¸ìš”.';
  }
  
  try {
    const systemPrompt = `ë‹¹ì‹ ì€ ì •ìš°íŠ¹ìˆ˜ì½”íŒ…ì˜ ì „ë¬¸ ì±—ë´‡ì…ë‹ˆë‹¤. 

ğŸ¢ **íšŒì‚¬ ì •ë³´:**
- ì •ìš°íŠ¹ìˆ˜ì½”íŒ…ì€ 1999ë…„ ì„¤ë¦½ëœ ì¸ì‡„ì½”íŒ… í›„ê°€ê³µ ì „ë¬¸ ê¸°ì—…ì…ë‹ˆë‹¤.
- 20ë…„ ì´ìƒì˜ ê²½í—˜ê³¼ ë…¸í•˜ìš°ë¥¼ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤.
- ìµœì‹  ì¥ë¹„ì™€ ìˆ™ë ¨ëœ ê¸°ìˆ ì§„, ì² ì €í•œ í’ˆì§ˆ ê´€ë¦¬ ì‹œìŠ¤í…œì„ ë³´ìœ í•©ë‹ˆë‹¤.

ğŸ¨ **ì£¼ìš” ì„œë¹„ìŠ¤:**
1. **UV ì½”íŒ…**: ìì™¸ì„ ìœ¼ë¡œ ê²½í™”ì‹œí‚¤ëŠ” ì½”íŒ… ë°©ì‹
   - ë¹ ë¥¸ ê±´ì¡° ì‹œê°„ê³¼ ë›°ì–´ë‚œ ê´‘íƒê°
   - ëª…í•¨, ì¹´íƒˆë¡œê·¸, í¬ìŠ¤í„° ë“±ì— ì ìš©
   - ë‚´êµ¬ì„±ì´ ìš°ìˆ˜í•˜ì—¬ ì˜¤ë˜ë„ë¡ ê¹¨ë—í•œ ìƒíƒœ ìœ ì§€

2. **ë¼ë¯¸ë„¤ì´íŒ…**: ì¸ì‡„ë¬¼ í‘œë©´ì— ì–‡ì€ í•„ë¦„ì„ ë¶€ì°©
   - ìœ ê´‘, ë¬´ê´‘, ë²¨ë²³ ë“± ë‹¤ì–‘í•œ í•„ë¦„ ì‚¬ìš©
   - ì¸ì‡„ë¬¼ í‘œë©´ ë³´í˜¸ ë° ì§ˆê° í–¥ìƒ
   - ì±… í‘œì§€, íŒ¨í‚¤ì§€, ë©”ë‰´íŒ ë“±ì— ìµœì 

3. **ë°• ì½”íŒ…**: ê¸ˆì† ë°•ë§‰ì„ ì¸ì‡„ë¬¼ì— ì „ì‚¬
   - ê¸ˆë°•, ì€ë°•, í™€ë¡œê·¸ë¨ ë°• ë“± ë‹¤ì–‘í•œ ì¢…ë¥˜
   - í™”ë ¤í•˜ê³  ê³ ê¸‰ìŠ¤ëŸ¬ìš´ íš¨ê³¼ ì—°ì¶œ
   - ëª…í•¨, ì´ˆëŒ€ì¥, íŒ¨í‚¤ì§€ ë“±ì— í™œìš©

4. **í˜•ì•• ê°€ê³µ**: ì••ë ¥ì„ ê°€í•´ ì…ì²´ì ì¸ íš¨ê³¼ ì—°ì¶œ
   - ì–‘ê°(ëŒì¶œ), ìŒê°(ë“¤ì–´ê°) íš¨ê³¼
   - ë…íŠ¹í•œ ì´‰ê°ê³¼ ì‹œê°ì  ì•„ë¦„ë‹¤ì›€
   - ë¡œê³ , í…ìŠ¤íŠ¸, íŒ¨í„´ ë“±ì— í™œìš©

ğŸ“ **ì—°ë½ì²˜ ì •ë³´:**
- ì „í™”: 02-1234-5678
- ì´ë©”ì¼: jwcoating@example.com
- ì˜¨ë¼ì¸ ë¬¸ì˜ í¼ ì´ìš© ê°€ëŠ¥
- ë¬´ë£Œ ìƒë‹´ ì„œë¹„ìŠ¤ ì œê³µ

${context ? `\nğŸ“‹ **ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸:**\n${context}` : ''}

**ë‹µë³€ ì§€ì¹¨:**
- í•­ìƒ ì¹œì ˆí•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
- ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•˜ê³ , ë¶ˆí™•ì‹¤í•œ ë‚´ìš©ì€ ë‹´ë‹¹ì ë¬¸ì˜ë¥¼ ì•ˆë‚´í•˜ì„¸ìš”.
- êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”.
- íšŒì‚¬ ì •ë³´ì™€ ì„œë¹„ìŠ¤ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰í•˜ì„¸ìš”.
- ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ì—¬ ì¹œê·¼í•¨ì„ í‘œí˜„í•˜ì„¸ìš”.`;

    const messages = [
      { role: 'system' as const, content: systemPrompt },
      ...conversationHistory.slice(-6), // ìµœê·¼ 6ê°œ ëŒ€í™”ë§Œ í¬í•¨
      { role: 'user' as const, content: userMessage }
    ];

    const completion = await openai.chat.completions.create({
      model: process.env.OPENAI_MODEL || 'gpt-3.5-turbo',
      messages,
      max_tokens: 800,
      temperature: 0.7,
      presence_penalty: 0.1,
      frequency_penalty: 0.1,
    });

    const response = completion.choices[0]?.message?.content;
    
    if (!response) {
      throw new Error('OpenAI API ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.');
    }

    return response.trim();
  } catch (error) {
    console.error('OpenAI API ì˜¤ë¥˜:', error);
    throw new Error('AI ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
  }
}

// í† í° ì‚¬ìš©ëŸ‰ ì¶”ì  í•¨ìˆ˜
export function calculateTokenUsage(messages: Array<{role: string, content: string}>): number {
  // ê°„ë‹¨í•œ í† í° ì¶”ì • (ì‹¤ì œë¡œëŠ” tiktoken ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ê¶Œì¥)
  return messages.reduce((total, message) => {
    return total + Math.ceil(message.content.length / 4); // ëŒ€ëµì ì¸ í† í° ê³„ì‚°
  }, 0);
}

// ë¹„ìš© ê³„ì‚° í•¨ìˆ˜ (GPT-3.5-turbo ê¸°ì¤€)
export function calculateCost(inputTokens: number, outputTokens: number): number {
  const inputCostPer1K = 0.001; // $0.001 per 1K tokens
  const outputCostPer1K = 0.002; // $0.002 per 1K tokens
  
  return (inputTokens / 1000 * inputCostPer1K) + (outputTokens / 1000 * outputCostPer1K);
}
