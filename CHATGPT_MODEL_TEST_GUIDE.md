# ChatGPT 모델 버전 테스트 가이드

## 🎯 테스트 목적

Gemini API로 전환하기 전에, ChatGPT의 더 강력한 모델 버전을 테스트하여 프롬프트 준수 능력이 개선되는지 확인합니다.

## 📊 테스트 가능한 모델 비교

### 1. gpt-3.5-turbo (현재 사용 중)
- **비용**: 저렴 ($0.0015 / 1K input tokens)
- **프롬프트 준수**: ⚠️ 보통 (긴 프롬프트 시 일부 무시 가능)
- **간결성 지시**: ⚠️ 완벽히 따르지 못할 수 있음
- **장점**: 빠르고 저렴
- **단점**: 프롬프트를 완벽히 따르지 못할 수 있음

### 2. gpt-4
- **비용**: 비쌈 ($0.03 / 1K input tokens)
- **프롬프트 준수**: ✅ 우수 (system prompt를 더 잘 따름)
- **간결성 지시**: ✅ 더 잘 준수
- **장점**: 프롬프트 지시사항을 더 정확히 따름
- **단점**: 비용이 높고 응답이 느림

### 3. gpt-4-turbo
- **비용**: 중간 ($0.01 / 1K input tokens)
- **프롬프트 준수**: ✅ 매우 우수
- **간결성 지시**: ✅ 매우 잘 준수
- **장점**: GPT-4보다 빠르고 저렴하면서도 강력
- **단점**: 여전히 gpt-3.5-turbo보다 비쌈

### 4. gpt-4o (최신)
- **비용**: 중간 ($0.005 / 1K input tokens)
- **프롬프트 준수**: ✅ 매우 우수
- **간결성 지시**: ✅ 매우 잘 준수
- **장점**: 최신 모델, 빠르고 효율적
- **단점**: 비교적 새로운 모델 (안정성 확인 필요)

### 5. gpt-3.5-turbo-16k
- **비용**: 저렴 ($0.003 / 1K input tokens)
- **프롬프트 준수**: ⚠️ 보통 (gpt-3.5-turbo와 유사)
- **간결성 지시**: ⚠️ 보통
- **장점**: 긴 프롬프트 처리 가능
- **단점**: 프롬프트 준수 능력은 gpt-3.5-turbo와 유사

## 🚀 테스트 방법

### 방법 1: 환경 변수로 변경 (가장 간단)

`.env.local` 파일 수정:
```env
# 기존
OPENAI_MODEL=gpt-3.5-turbo

# 테스트 1: GPT-4
OPENAI_MODEL=gpt-4

# 테스트 2: GPT-4 Turbo
OPENAI_MODEL=gpt-4-turbo

# 테스트 3: GPT-4o (최신)
OPENAI_MODEL=gpt-4o

# 테스트 4: GPT-3.5 Turbo 16K
OPENAI_MODEL=gpt-3.5-turbo-16k
```

**주의**: Vercel 배포 시에도 환경 변수를 업데이트해야 합니다.

### 방법 2: 코드에서 직접 테스트 (임시)

`lib/openai.ts` 파일에서 직접 모델명 변경:
```typescript
const completion = await openai.chat.completions.create({
  model: 'gpt-4-turbo', // 테스트할 모델명으로 변경
  messages,
  max_tokens: 200,
  temperature: 0.3,
  presence_penalty: 0.3,
  frequency_penalty: 0.3
});
```

## 📝 테스트 체크리스트

각 모델로 테스트할 때 다음 질문들로 확인:

### 테스트 질문 1: 간결성
```
질문: "견적이 궁금해요"
기대 결과: 간결한 답변 (2-3줄 이내)
```

### 테스트 질문 2: 반문 능력
```
질문: "코팅이 필요해요"
기대 결과: 추가 질문 (어떤 코팅 서비스를 원하시나요?)
```

### 테스트 질문 3: 프롬프트 준수
```
질문: "연락처 알려줘"
기대 결과: 프롬프트에 명시된 연락처만 간결하게 제공
```

### 테스트 질문 4: 맥락 이해
```
질문: "UV 코팅 견적이 궁금해요"
기대 결과: UV 코팅 관련 정보만 간결하게 제공
```

## 📊 예상 결과 비교

### gpt-3.5-turbo (현재)
```
질문: "견적이 궁금해요"
답변: "견적 문의를 도와드리겠습니다! 정우특수코팅은 1999년 설립된... (장황한 답변)"
```

### gpt-4-turbo (예상)
```
질문: "견적이 궁금해요"
답변: "어떤 코팅 서비스를 원하시나요? (UV 코팅/라미네이팅/박 코팅/형압 가공) 수량과 크기를 알려주시면 견적을 드립니다."
```

## 💡 추천 테스트 순서

### 1단계: gpt-4-turbo 테스트 (우선)
- **이유**: GPT-4의 강력함 + 상대적으로 저렴한 비용
- **예상 효과**: 70-80% 개선 가능
- **비용**: gpt-3.5-turbo의 약 6-7배

### 2단계: gpt-4o 테스트
- **이유**: 최신 모델, 빠르고 효율적
- **예상 효과**: gpt-4-turbo와 유사하거나 더 나을 수 있음
- **비용**: gpt-3.5-turbo의 약 3-4배

### 3단계: gpt-4 테스트 (비용 고려 시)
- **이유**: 가장 강력하지만 비용이 높음
- **예상 효과**: 80-90% 개선 가능
- **비용**: gpt-3.5-turbo의 약 20배

## ⚠️ 주의사항

### 1. 비용 관리
- GPT-4 계열은 비용이 높습니다
- 테스트 후 실제 사용량에 따른 비용 계산 필요
- 무료 크레딧으로 먼저 테스트 권장

### 2. 응답 속도
- GPT-4 계열은 응답이 느릴 수 있습니다
- 사용자 경험에 영향이 있는지 확인 필요

### 3. API 제한
- GPT-4는 사용량 제한이 있을 수 있습니다
- Rate limit 확인 필요

## 🎯 최종 판단 기준

### GPT-4 계열이 효과적이라면:
- ✅ 프롬프트를 더 잘 따름
- ✅ 간결한 답변 생성
- ✅ NotebookLM 수준에 근접
- → **GPT-4 계열 사용 계속** 또는 **Gemini API와 비교**

### GPT-4 계열도 부족하다면:
- ❌ 여전히 프롬프트를 제대로 따르지 못함
- ❌ 비용 대비 효과가 낮음
- → **Gemini API 전환 고려**

## 📝 테스트 결과 기록

테스트 후 다음 정보를 기록하세요:

```
모델: gpt-4-turbo
테스트 날짜: 2024-XX-XX

질문 1: "견적이 궁금해요"
답변: [실제 답변]
평가: [간결성, 프롬프트 준수, 맥락 이해 등]

질문 2: "코팅이 필요해요"
답변: [실제 답변]
평가: [반문 능력, 정보 추출 등]

비용: [예상 비용]
결론: [효과적/비효과적, Gemini API 전환 필요 여부]
```

## 🚀 빠른 테스트 시작

1. `.env.local` 파일 열기
2. `OPENAI_MODEL=gpt-4-turbo`로 변경
3. 서버 재시작
4. 챗봇에서 테스트 질문 입력
5. 결과 확인 및 비교

이렇게 하면 빠르게 테스트할 수 있습니다! 🎯

